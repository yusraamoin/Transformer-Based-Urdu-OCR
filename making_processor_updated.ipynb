{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_rmekvjh-omy"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoFeatureExtractor, AutoTokenizer\n",
    "from transformers import TrOCRProcessor, VisionEncoderDecoderModel\n",
    "image_processor = AutoFeatureExtractor.from_pretrained(\"google/vit-base-patch16-384\")\n",
    "decoder_tokenizer = AutoTokenizer.from_pretrained(\"urduhack/roberta-urdu-small\")\n",
    "\n",
    "#processor = TrOCRProcessor(feature_extractor=feature_extractor, tokenizer=decoder_tokenizer)\n",
    "processor = TrOCRProcessor(image_processor=image_processor, tokenizer=decoder_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PYBr94va_jv0"
   },
   "outputs": [],
   "source": [
    "# processor.save_pretrained('../test/test_processor')\n",
    "processor.save_pretrained('./preprocessor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KfqpUIo15AS4",
    "outputId": "f521f9a8-0aa8-46a0-b0cd-31a2c24a1a8b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "df = pd.read_excel(\"./data/sen_dataset.xlsx\", header=None)\n",
    "df.rename(columns={0: \"filename\", 1: \"text\"}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L4sMaHuQ5gTV"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.3)\n",
    "\n",
    "train_df.reset_index(drop=True, inplace=True)\n",
    "test_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6hyna5wS5hX4"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class IAMDataset(Dataset):\n",
    "    def __init__(self, root_dir, df, processor, max_target_length=128):\n",
    "        self.root_dir = root_dir\n",
    "        self.df = df\n",
    "        self.processor = processor\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # get file name + text \n",
    "        file_name = self.df['filename'][idx]\n",
    "        text = self.df['text'][idx]\n",
    "        # prepare image (i.e. resize + normalize)\n",
    "        image = Image.open(self.root_dir + file_name).convert(\"RGB\")\n",
    "        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n",
    "        # add labels (input_ids) by encoding the text\n",
    "        labels = self.processor.tokenizer(text, padding=\"max_length\",max_length=self.max_target_length).input_ids\n",
    "        # important: make sure that PAD tokens are ignored by the loss function\n",
    "        labels = [label if label != self.processor.tokenizer.pad_token_id else -100 for label in labels]\n",
    "\n",
    "        encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(labels)}\n",
    "        return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DMa6KXH15wsx"
   },
   "outputs": [],
   "source": [
    "from transformers import TrOCRProcessor\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained(\"./preprocessor/\")\n",
    "\n",
    "train_dataset = IAMDataset(root_dir= \"./data/images/\",\n",
    "                           df = train_df,\n",
    "                           processor=processor)\n",
    "\n",
    "eval_dataset = IAMDataset(root_dir= \"./data/images/\",\n",
    "                           df = test_df,\n",
    "                           processor = processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zS0V-GTS6YkT",
    "outputId": "295fe667-b17a-498e-e49c-12df1bf6ade1"
   },
   "outputs": [],
   "source": [
    "print(\"Number of training examples:\", len(train_dataset))\n",
    "print(\"Number of validation examples:\", len(eval_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 63
    },
    "id": "tRgMIlp06dA-",
    "outputId": "dde67c5a-8005-4d4a-f794-5c21974faab0"
   },
   "outputs": [],
   "source": [
    "image = Image.open(train_dataset.root_dir + train_df['filename'][6]).convert(\"RGB\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c69U-3YH6cMF",
    "outputId": "7548d140-bb31-4d81-a6a3-dd06b45d70d1"
   },
   "outputs": [],
   "source": [
    "encoding = train_dataset[6]\n",
    "for k,v in encoding.items():\n",
    "    print(k, v.shape)\n",
    "    \n",
    "labels = encoding['labels']\n",
    "labels[labels == -100] = processor.tokenizer.pad_token_id\n",
    "label_str = processor.decode(labels, skip_special_tokens=True)\n",
    "print(label_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vrJ3ojeJA6n9"
   },
   "outputs": [],
   "source": [
    "from transformers import VisionEncoderDecoderModel\n",
    "\n",
    "model = VisionEncoderDecoderModel.from_encoder_decoder_pretrained(\"google/vit-base-patch16-384\", \n",
    "                                                                  \"urduhack/roberta-urdu-small\")\n",
    "\n",
    "# set decoder config to causal lm\n",
    "model.config.decoder.is_decoder = True\n",
    "model.config.decoder.add_cross_attention = True\n",
    "\n",
    "# set special tokens used for creating the decoder_input_ids from the labels\n",
    "model.config.decoder_start_token_id = processor.tokenizer.cls_token_id\n",
    "model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "\n",
    "# make sure vocab size is set correctly\n",
    "model.config.vocab_size = model.config.decoder.vocab_size\n",
    "\n",
    "# set beam search parameters\n",
    "model.config.eos_token_id = processor.tokenizer.sep_token_id\n",
    "model.config.max_length = 64\n",
    "model.config.early_stopping = True\n",
    "model.config.no_repeat_ngram_size = 3\n",
    "model.config.length_penalty = 2.0\n",
    "model.config.num_beams = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xz9lc08aF7pr"
   },
   "source": [
    "# Evaluating using epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-AHdsYMFe__"
   },
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "   evaluation_strategy = \"epoch\",\n",
    "   learning_rate= 0.002,\n",
    "   per_device_train_batch_size = 32,\n",
    "   per_device_eval_batch_size = 8,\n",
    "   weight_decay = 0.01,\n",
    "   save_total_limit = 2,\n",
    "   num_train_epochs = 40,\n",
    "   output_dir = \"./train/\",\n",
    "   predict_with_generate=True,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "cer_metric = evaluate.load('cer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vOYddNXnBxr2"
   },
   "outputs": [],
   "source": [
    "def compute_metrics(pred):\n",
    "    labels_ids = pred.label_ids\n",
    "    pred_ids = pred.predictions\n",
    "\n",
    "    pred_str = processor.batch_decode(pred_ids, skip_special_tokens=True)\n",
    "    labels_ids[labels_ids == -100] = processor.tokenizer.pad_token_id\n",
    "    label_str = processor.batch_decode(labels_ids, skip_special_tokens=True)\n",
    "\n",
    "    cer = cer_metric.compute(predictions=pred_str, references=label_str)\n",
    "\n",
    "    return {\"cer\": cer}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 857
    },
    "id": "8k_Ufd6HB1Px",
    "outputId": "b353a36c-4a7f-4ac5-fc74-adc684c27e9f"
   },
   "outputs": [],
   "source": [
    "from transformers import default_data_collator\n",
    "\n",
    "# instantiate trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "                        model = model,\n",
    "                        tokenizer = processor.feature_extractor,\n",
    "                        args = training_args,\n",
    "                        compute_metrics = compute_metrics,\n",
    "                        train_dataset = train_dataset,\n",
    "                        eval_dataset = eval_dataset,\n",
    "                        data_collator = default_data_collator\n",
    "                        )\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D3J3XGY6GfkD",
    "outputId": "222ddded-d50a-4665-a17d-e368098cd42e"
   },
   "outputs": [],
   "source": [
    "trainer.save_model('./trainings/models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jzfohl8wG2J2"
   },
   "outputs": [],
   "source": [
    "model = VisionEncoderDecoderModel.from_pretrained(\"./trainer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "okXisArpHLzQ"
   },
   "outputs": [],
   "source": [
    "image = Image.open('./dat').convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "id": "VQnwWb5LPngA",
    "outputId": "ad2f69b3-90e2-4e4b-c1ac-69bffb78fc09"
   },
   "outputs": [],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A5MR7dxhHR7W",
    "outputId": "7f68d1ae-71e9-425f-cac1-a427faaba681"
   },
   "outputs": [],
   "source": [
    "pixel_values = processor.feature_extractor(image, return_tensors=\"pt\").pixel_values \n",
    "print(pixel_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2e4ruhWiHp4-",
    "outputId": "d380e4cd-9e85-4285-8ae1-51a9a682acd7"
   },
   "outputs": [],
   "source": [
    "generated_ids = model.generate(pixel_values)\n",
    "generated_text = processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QHTWc4xjd3_b",
    "outputId": "38f9d4a8-2f5b-4f53-8c42-c093c3cad65e"
   },
   "outputs": [],
   "source": [
    "test = Image.open('/content/8.png').convert(\"RGB\")\n",
    "testvalues = processor.feature_extractor(test, return_tensors=\"pt\").pixel_values \n",
    "print(testvalues.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-pHS_LzceBgO",
    "outputId": "e422ed6d-cc96-49b0-9d3c-2582faf0e03e"
   },
   "outputs": [],
   "source": [
    "testids = model.generate(testvalues)\n",
    "testtext = processor.batch_decode(testids, skip_special_tokens=True)[0]\n",
    "print(testtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO0Ion1FGgkKT7q480ryU2r",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "making_processor.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "easyocr-env",
   "language": "python",
   "name": "easyocr-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
